{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Thinking1：\n",
    "有监督学习：有训练数据又有标签（label）；\n",
    "无监督学习：有训练数据无标签；\n",
    "半监督学习：小部分训练数据有标签，更多的训练数据无标签。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Thinking2:\n",
    "用不同的k值，寻找loss值下降最快的点（手肘法）。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Thinking3：\n",
    "bagging算法，俗称装袋法，使用了boostrap思想，从样本中又放回的抽取n个样本，得到一个训练集，并构造了一个弱分类器，重复构造多个弱分类器，在做决策时，按权重进行预测。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Thinking4：\n",
    "半监督学习是因为原始数据不够，用无label的数据来进行提高模型；\n",
    "表征学习是对原始复杂的信息进行化简，提取有效信息，提升模型精度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.metrics import recall_score,accuracy_score,precision_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>证券时报网</td>\n",
       "      <td>证券时报网（www.stcn.com）06月23日讯\\r\\n　　据上证报道，6月初以来，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>证券时报网</td>\n",
       "      <td>?\\r\\n　　巨丰早评：市场将再次探底\\r\\n　　【巨丰观点】\\r\\n　　周四大盘冲高回落，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>中国新闻网</td>\n",
       "      <td>中新网6月19日电 据外媒报道，美国底特律一名男子1976年因为一根头发被定谋杀罪，监禁41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>中国证券报?中证网</td>\n",
       "      <td>曹先生：风格转换前的阵痛\\r\\n　　今日早盘两地低开，之后一度震荡走高，领涨的仍然是上证...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>国际在线</td>\n",
       "      <td>6月21日，MSCI在官网发布公告称，从明年6月起将中国A股纳入MSCI新兴市场指数和MSC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                            content\n",
       "0      证券时报网  　　证券时报网（www.stcn.com）06月23日讯\\r\\n　　据上证报道，6月初以来，...\n",
       "1      证券时报网  ?\\r\\n　　巨丰早评：市场将再次探底\\r\\n　　【巨丰观点】\\r\\n　　周四大盘冲高回落，...\n",
       "2      中国新闻网  中新网6月19日电 据外媒报道，美国底特律一名男子1976年因为一根头发被定谋杀罪，监禁41...\n",
       "3  中国证券报?中证网  　　曹先生：风格转换前的阵痛\\r\\n　　今日早盘两地低开，之后一度震荡走高，领涨的仍然是上证...\n",
       "4       国际在线  6月21日，MSCI在官网发布公告称，从明年6月起将中国A股纳入MSCI新兴市场指数和MSC..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据加载\n",
    "data = pd.read_csv('G:/git/python检查文章、新闻、字段的抄袭情况/sqlResult.csv',encoding = 'gb18030' )\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step2.数据预处理1.删除content、source为空的行\n",
    "data = data.dropna(axis=0,subset=['content'])\n",
    "data = data.dropna(axis = 0,subset = ['source'])\n",
    "#print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['，', '的', '。', '、', '在', '了', '是', '\\u3000', '“', '”', '和', '年', '月', '：', '也', '）', '为', '（', '有', '%', '日', '将', '中', '-', '到', '与', '对', ':', '\\xa0', '上', '都', '等', '不', '他', '》', '《', '就', '但', '我', '而', '这', '会', '并', '；', '被', '后', '人', '从', '还', '1', '3', '6', '以', '新', '说', '7', '2', '要', '5', '？', '更', '于', '个', '10', '大', '时', '4', '多', '/', '让', '其', ')', '(', '很', '及', '下', '', '能', '—', '或', '该', '她', '比', '8', '元', '12', '已', '向', '做', '来', '前', '由', '好', '.', '称', '给', '最', '11', '·', '据', '着', '又', '至', '9', '20', '！', '[', ']', '去', '可', '把', '则', '', '一', '地', '高', '吗', '30', '所', '分', '较', '内', '第', '里', '占', '过', '15', '曾', '\"', '再', '人民日报', '新闻网', '它', '况', '而且', '而是', '而外', '而言', '而已', '尔后', '反过来', '反过来说', '反之', '非但', '非徒', '否则', '嘎', '嘎登', '该', '赶', '个', '各', '各个', '各位', '各种', '各自', '给', '根据', '跟', '故', '故此', '固然', '关于', '管', '归', '果然', '果真', '过', '哈', '哈哈', '呵', '和', '何', '何处', '何况', '何时', '嘿', '哼', '哼唷', '呼哧', '乎', '哗', '还是', '还有', '换句话说', '换言之', '或', '或是', '或者', '极了', '及', '及其', '及至', '即', '即便', '即或', '即令', '即若', '即使', '几', '几时', '己', '既', '既然', '既是', '继而', '加之', '假如', '假若', '假使', '鉴于', '将', '较', '较之', '叫', '接着', '结果', '借', '紧接着', '进而', '尽', '尽管', '经', '经过', '就', '就是', '就是说', '据', '具体地说', '具体说来', '开始', '开外', '靠', '咳', '可', '可见', '可是', '可以', '况且', '啦', '来', '来着', '离', '例如', '哩', '连', '连同', '两者', '了', '临', '另', '另外', '另一方面', '论', '嘛', '吗', '慢说', '漫说', '冒', '么', '每', '每当', '们', '莫若', '某', '某个', '某些', '拿', '哪', '哪边', '哪儿', '哪个', '哪里', '哪年', '哪怕', '哪天', '哪些', '哪样', '那', '那边', '那儿', '那个', '那会儿', '那里', '那么', '那么些', '那么样', '那时', '那些', '那样', '乃', '乃至', '呢', '能', '你', '你们', '您', '宁', '宁可', '宁肯', '宁愿', '哦', '呕', '啪达', '旁人', '呸', '凭', '凭借', '其', '其次', '其二', '其他', '其它', '其一', '其余', '其中', '起', '起见', '起见', '岂但', '恰恰相反', '前后', '前者', '且', '然而', '然后', '然则', '让', '人家', '任', '任何', '任凭', '如', '如此', '如果', '如何', '如其', '如若', '如上所述', '若非', '若是', '啥', '上下', '尚且', '设若', '设使', '甚而', '甚么', '甚至', '省得', '时候', '什么', '什么样', '使得', '是', '是的', '首先', '谁', '谁知', '顺', '顺着', '似的', '虽', '虽然', '虽说', '虽则', '随', '随着', '所', '所以', '他', '他们', '他人', '它', '它们', '她', '她们', '倘', '倘或', '倘然', '倘若', '倘使', '腾', '替', '通过', '同', '同时', '哇', '万一', '往', '望', '为', '为何', '为了', '为什么', '为着', '喂', '嗡嗡', '我', '我们', '呜', '呜呼', '乌乎', '无论', '无宁', '毋宁', '嘻', '吓', '相对而言', '像', '向', '向着', '嘘', '呀', '焉', '沿', '沿着', '要', '要不', '要不然', '要不是', '要么', '要是', '也', '也罢', '也好', '一', '一般', '一旦', '一方面', '一来', '一切', '一样', '一则', '依', '依照', '矣', '以', '以便', '以及', '以免', '以至', '以至于', '以致', '抑或', '因', '因此', '因而', '因为', '哟', '用', '由', '由此可见', '由于', '有', '有的', '有关', '有些', '又', '于', '于是', '于是乎', '与', '与此同时', '与否', '与其', '越是', '云云', '哉', '再说', '再者', '在', '在下', '咱', '咱们', '则', '怎', '怎么', '怎么办', '怎么样', '怎样', '咋', '照', '照着', '者', '这', '这边', '这儿', '这个', '这会儿', '这就是说', '这里', '这么', '这么点儿', '这么些', '这么样', '这时', '这些', '这样', '正如', '吱', '之', '之类', '之所以', '之一', '只是', '只限', '只要', '只有', '至', '至于', '诸位', '着', '着呢', '自', '自从', '自个儿', '自各儿', '自己', '自家', '自身', '综上所述', '总的来看', '总的来说', '总的说来', '总而言之', '总之', '纵', '纵令', '纵然', '纵使', '遵照', '作为', '兮', '呃', '呗', '咚']\n",
      "　　证券时报网（www.stcn.com）06月23日讯\r\n",
      "　　据上证报道，6月初以来，创业板指数明显强于上证综指，一时间关于蓝筹行情将向成长股行情切换的预期再起。但多位私募人士表示，蓝筹股与成长股这两年并非绝对的此消彼长。本轮蓝筹股上涨行情的主要推动力就是业绩成长，而业绩与估值匹配才是王道。上述私募人士依然看好成长性突出的蓝筹股。\r\n",
      "\n",
      "证券时报 网 www stcn com 06 23 日讯 \r\n",
      " 上证 报道 月初 以来 创业板 指数 明显 强于 上证综指 一时间 蓝筹 行情 成长 股行情 切换 预期 再起 多位 私募 人士 表示 蓝筹股 成长 股 两年 并非 绝对 此消彼长 本轮 蓝筹股 上涨 行情 主要 推动力 业绩 成长 业绩 估值 匹配 才 王道 上述 私募 人士 依然 看好 成长性 突出 蓝筹股 \r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2.结巴分词+加载停用词\n",
    "with open('G:/git/python检查文章、新闻、字段的抄袭情况/chinese_stopwords.txt',encoding='utf-8') as file:\n",
    "    stopwords = [i[:-1] for i in file.readlines()]\n",
    "def word_split(text):\n",
    "    text = text.replace(' ','').replace('/n','')\n",
    "    text2 = jieba.cut(text)\n",
    "    result = ' '.join([t for t in text2 if t not in stopwords])\n",
    "    return result\n",
    "print(stopwords)\n",
    "print(data.iloc[0].content)\n",
    "print(word_split(data.iloc[0].content))\n",
    "corpus = list(map(word_split,[str(i) for i in data.content]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 872)\t0.2748530113256343\n",
      "  (0, 751)\t0.1599775402306061\n",
      "  (0, 680)\t0.275536443497438\n",
      "  (0, 541)\t0.24225528190125376\n",
      "  (0, 483)\t0.2765781627658592\n",
      "  (0, 474)\t0.201034310506804\n",
      "  (0, 167)\t0.26523990159520294\n",
      "  (0, 145)\t0.20082444910636033\n",
      "  (0, 129)\t0.495278556655558\n",
      "  (0, 103)\t0.1898018275595141\n",
      "  (0, 87)\t0.2681572143273556\n",
      "  (0, 63)\t0.26739648803453225\n",
      "  (0, 62)\t0.26926784288473765\n",
      "  (0, 14)\t0.19855021923226232\n",
      "  (1, 878)\t0.044777531795851845\n",
      "  (1, 873)\t0.04186966757610768\n",
      "  (1, 865)\t0.041079580613136546\n",
      "  (1, 861)\t0.12729721112473844\n",
      "  (1, 859)\t0.04617035623718872\n",
      "  (1, 849)\t0.27343142416141625\n",
      "  (1, 844)\t0.04030710844140916\n",
      "  (1, 832)\t0.04993485406473139\n",
      "  (1, 818)\t0.08290372138929573\n",
      "  (1, 811)\t0.03993774548205976\n",
      "  (1, 806)\t0.0804476074095681\n",
      "  :\t:\n",
      "  (87051, 225)\t0.05160074917487412\n",
      "  (87051, 216)\t0.12471484046406585\n",
      "  (87051, 211)\t0.05310357891749532\n",
      "  (87051, 208)\t0.09808041994954449\n",
      "  (87051, 171)\t0.054267720606178425\n",
      "  (87051, 157)\t0.05462116405416567\n",
      "  (87051, 151)\t0.058345383658049796\n",
      "  (87051, 133)\t0.23360381145329054\n",
      "  (87051, 120)\t0.05241018002290733\n",
      "  (87051, 110)\t0.17793892244698892\n",
      "  (87051, 108)\t0.10260638738949618\n",
      "  (87051, 107)\t0.05790377250861003\n",
      "  (87051, 106)\t0.03065865038498838\n",
      "  (87051, 81)\t0.03965533835961951\n",
      "  (87051, 76)\t0.10591232849425448\n",
      "  (87051, 74)\t0.1569138199354545\n",
      "  (87051, 61)\t0.09820714667048525\n",
      "  (87051, 58)\t0.06056923616295204\n",
      "  (87051, 52)\t0.05042597519528592\n",
      "  (87051, 46)\t0.05990742137507215\n",
      "  (87051, 42)\t0.05360267106698506\n",
      "  (87051, 40)\t0.061594314460956326\n",
      "  (87051, 37)\t0.05649157311108067\n",
      "  (87051, 35)\t0.04537566601075908\n",
      "  (87051, 34)\t0.25988142849836504\n"
     ]
    }
   ],
   "source": [
    "#step3.查看文本的特征，TFIDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "countVectorizer = CountVectorizer(encoding='gb18030',min_df=0.015)\n",
    "tfidfTransformer = TfidfTransformer()\n",
    "countVectorizer = countVectorizer.fit_transform(corpus)\n",
    "tfidfTransformer = tfidfTransformer.fit_transform(countVectorizer)\n",
    "print(tfidfTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB的准确率 0.8878869680087301\n",
      "MultinomialNB的精确率 0.9646047417556586\n",
      "MultinomialNB的召回率 0.9097358586178501\n"
     ]
    }
   ],
   "source": [
    "#step4标记是否为新华社文章,切分数据集\n",
    "label = list(map(lambda i:1 if '新华社' in str(i) else 0,data.source))\n",
    "#数据集切分\n",
    "x_train,x_test,y_train,y_test = train_test_split(tfidfTransformer.toarray(),label,test_size=0.2)\n",
    "#多项式朴素贝叶斯、伯努利贝叶斯分类准确率\n",
    "model_m = MultinomialNB()\n",
    "model_m.fit(x_train,y_train)\n",
    "pred_m = model_m.predict(x_test)\n",
    "print('MultinomialNB的准确率',accuracy_score(y_test,pred_m))\n",
    "print('MultinomialNB的精确率',precision_score(y_test,pred_m))\n",
    "print('MultinomialNB的召回率',recall_score(y_test,pred_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "可能为copy的新闻条数： 2784\n"
     ]
    }
   ],
   "source": [
    "#step5.预测文章风格是否和自己一致\n",
    "prediction = model_m.predict(tfidfTransformer.toarray())\n",
    "label = np.array(label)\n",
    "compare = pd.DataFrame({'label':label , 'pred':prediction})\n",
    "copy_index= compare[(compare['label'] == 0)&(compare['pred']==1)].index\n",
    "print('可能为copy的新闻条数：',len(copy_index))\n",
    "#实际为新华社的新闻\n",
    "xinhuashe_news_index = compare[(compare['label'] == 1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step6 对tfidf.toarray()进行聚类降维\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.cluster import KMeans\n",
    "normalizer = Normalizer()\n",
    "scale_array = normalizer.fit_transform(tfidfTransformer.toarray())\n",
    "kmeans = KMeans(n_clusters=25)\n",
    "k_label = kmeans.fit_predict(scale_array)\n",
    "#对分类创建序号\n",
    "id_class = {index:class_ for index,class_ in enumerate(k_label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step7创建新华社发布的字典\n",
    "from collections import defaultdict\n",
    "class_id = defaultdict(set)\n",
    "for index,class_ in id_class.items():\n",
    "    if index in xinhuashe_news_index.tolist():\n",
    "        class_id[class_].add(index)\n",
    "#查找相似的文章\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#只在新华社发布的文章中查找\n",
    "def find_similar_text(cpindex,top=10):\n",
    "    dist_dict = {i:cosine_similarity(tfidfTransformer[cpindex],tfidfTransformer[i]) for i in class_id[id_class[cpindex]]}\n",
    "    return sorted(dist_dict.items(),key = lambda  x:x[1][0],reverse=True)[:top]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是否在新华社 False\n",
      "是否在copy_news False\n",
      "[(12024, array([[0.50824924]])), (61536, array([[0.48992039]])), (74254, array([[0.46678522]])), (74313, array([[0.46678522]])), (42564, array([[0.4597049]])), (66150, array([[0.45058751]])), (50065, array([[0.45026396]])), (37008, array([[0.44543087]])), (82581, array([[0.4418654]])), (34693, array([[0.44147324]]))]\n",
      "怀疑抄袭：\n",
      " 　　原标题：斯瑞德、鼎义互联、精英在线等3家公司今日挂牌新三板\n",
      "　　中国网财经6月6日讯 今日共有3家企业挂牌新三板，其中，协议转做市0家。截止今日，新三板市场总挂牌数达11263家，协议转让企业9703家，做市转让企业1560家；申报及待挂牌的企业共918家。\n",
      "　　今日挂牌企业信息一览：\n",
      "　　名称 主办券商 行业 斯瑞德\n",
      "　　871488 第一创业证券股份有限公司 资本品 鼎义互联\n",
      "　　871558 国融证券股份有限公司 软件与服务 精英在线\n",
      "　　871575 安信证券股份有限公司 软件与服务\n",
      "?\n",
      "\n",
      "相似的原文:\n",
      " 　　新华社北京１１月２５日电（记者王都鹏、刘慧）中国证监会２５日核准１４家企业的首发申请，这１４家企业的筹资总额预计不超过１１２亿元。\\n　　１４家企业中，有７家企业拟在上海证券交易所上市，包括亚翔系统集成科技（苏州）股份有限公司、贵州省广播电视信息网络股份有限公司、上海元祖梦果子股份有限公司、浙江华正新材料股份有限公司、杭叉集团股份有限公司、日月重工股份有限公司、中原证券股份有限公司。有３家企业拟在深圳证券交易所中小板上市，包括比音勒芬服饰股份有限公司、深圳市同为数码科技股份有限公司、广州弘亚数控机械股份有限公司。拟在创业板上市的４家企业，为北京数字认证股份有限公司、英飞特电子（杭州）股份有限公司、西安晨曦航空科技股份有限公司、无锡贝斯特精机股份有限公司。\\n　　证监会通报的信息显示，本次将有北京数字认证股份有限公司、西安晨曦航空科技股份有限公司等２家公司直接定价发行。上述企业及其承销商将分别与沪深交易所协商确定发行日程，并陆续刊登招股文件。（完）\n"
     ]
    }
   ],
   "source": [
    "#step8.如查找某一篇是否为copy的,如果是抄袭的，查看可能抄袭的文章\n",
    "cpindex = 2447\n",
    "print('是否在新华社',cpindex in xinhuashe_news_index)\n",
    "print('是否在copy_news',cpindex in copy_index)\n",
    "similar_list = find_similar_text(cpindex)\n",
    "print(similar_list)\n",
    "\n",
    "print('怀疑抄袭：\\n',data.iloc[cpindex].content)\n",
    "#找一篇相似的原文\n",
    "similar2 = similar_list[0][0]\n",
    "print('相似的原文:\\n',data.iloc[similar2].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
